{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_code(code, manual, R1_metadata, R2_metadata):\n",
    "    # checks that the code and manual are provided correctly and extracts the subject ID (code)  \n",
    "    if code == \"id\":\n",
    "        code_1 = R1_metadata[\"Subject ID\"].iloc[0]\n",
    "        code_2 = R2_metadata[\"Subject ID\"].iloc[0]\n",
    "    elif code == \"id+comment\":\n",
    "        code_1 = R1_metadata[\"Subject ID\"].iloc[0] + '_' + R1_metadata[\"Comments\"].iloc[0]\n",
    "        code_2 = R2_metadata[\"Subject ID\"].iloc[0] + '_' + R2_metadata[\"Comments\"].iloc[0]\n",
    "    elif code == \"manual\" or manual != None:\n",
    "        try:\n",
    "            code_1 = manual[0]\n",
    "            code_2 = manual[1]\n",
    "        except ValueError as e:\n",
    "            print(\"You have tried to enter a manual code (this is the filename that the metadata and data will be saved as). Please make sure your manual code is a list, e.g: ['1234_visit1', '5678_visit1'], where the first entry is for subject in room 1 and the second entry for subject in room 2.\")\n",
    "    else:\n",
    "        raise ValueError(\"The value for the code parameter is not valid. Please choose id, id+comment or manual. Default is id.\")\n",
    "    \n",
    "    return code_1, code_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_meta_data(lines, code, manual, save_csv, path_to_save):\n",
    "    header_lines = [line.strip().split('\\t') for line in lines[3:7]]\n",
    "\n",
    "    data_R1 = dict(zip(header_lines[0][1:], header_lines[1]))\n",
    "    data_R2 = dict(zip(header_lines[2][1:], header_lines[3]))\n",
    "\n",
    "    R1_metadata = pd.DataFrame([data_R1])\n",
    "    R2_metadata = pd.DataFrame([data_R2])\n",
    "\n",
    "    code_1, code_2 = check_code(code, manual, R1_metadata, R2_metadata)\n",
    "    \n",
    "    if save_csv:\n",
    "        room1_filename = f'{path_to_save}/{code_1}_WRIC_metadata.csv' if path_to_save else f'{code_1}_WRIC_metadata.csv'\n",
    "        room2_filename = f'{path_to_save}/{code_2}_WRIC_metadata.csv' if path_to_save else f'{code_2}_WRIC_metadata.csv'\n",
    "        R1_metadata.to_csv(room1_filename, index=False)\n",
    "        R2_metadata.to_csv(room2_filename, index=False)\n",
    "        \n",
    "    return code_1, code_2, R1_metadata, R2_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(filepath):\n",
    "    # Check that the provided filepath is valid and leads to a WRIC file\n",
    "    if not filepath.lower().endswith('.txt'):\n",
    "        raise TypeError(\"The file must be a .txt file.\")\n",
    "    try:\n",
    "        with open(filepath, \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "            if not lines or not lines[0].startswith(\"OmniCal software\"):\n",
    "                raise ValueError(\"The provided file is not the WRIC data file.\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(\"The filepath you provided does not lead to a file.\")\n",
    "        \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wric_df(filepath, lines, save_csv, code_1, code_2, path_to_save):\n",
    "    # find start of data line\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.startswith(\"Room 1 Set 1\"):  # Detect where the actual data starts\n",
    "            data_start_index = i + 1  # First data row starts after this\n",
    "            break\n",
    "    # Reading the data starting from where the table begins\n",
    "    df = pd.read_csv(filepath, sep=\"\\t\", skiprows=data_start_index)\n",
    "    # there are NaN rows after each Room&Set combination that need to be deleted\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "\n",
    "    # define the new column names\n",
    "    columns = [\n",
    "        \"Date\", \"Time\", \"VO2\", \"VCO2\", \"RER\", \"FiO2\", \"FeO2\", \"FiCO2\", \"FeCO2\", \n",
    "        \"Flow\", \"Activity Monitor\", \"Energy Expenditure (kJ/min)\", \"Energy Expenditure (kcal/min)\", \n",
    "        \"Pressure Ambient\", \"Temperature\", \"Relative Humidity\"\n",
    "    ]\n",
    "    new_columns = []\n",
    "    for set_num in ['S1', 'S2']:\n",
    "        for room in ['R1', 'R2']:\n",
    "            for col in columns:\n",
    "                new_columns.append(f\"{room}_{set_num}_{col}\")\n",
    "    df.columns = new_columns\n",
    "\n",
    "    # Check that time and date columns are consistent across rows\n",
    "    date_columns, time_columns = df.filter(like='Date'), df.filter(like='Time')\n",
    "    if not (date_columns.nunique(axis=1).eq(1).all() and time_columns.nunique(axis=1).eq(1).all()):\n",
    "        raise ValueError(\"Date or Time columns do not match in some rows\")\n",
    "\n",
    "    # Combine Date and Time to DateTime and drop all unecessary date/time columns\n",
    "    df_filtered = df.filter(like='Date').iloc[:, 0].to_frame(name=\"Date\").join(df.filter(like='Time').iloc[:, 0].to_frame(name=\"Time\"))\n",
    "    df_filtered['datetime'] = pd.to_datetime(df_filtered['Date'] + ' ' + df_filtered['Time'], format='%m/%d/%y %H:%M:%S')\n",
    "    df_filtered = df_filtered.drop(columns=['Date', 'Time'])\n",
    "    df = df_filtered.join(df.drop(columns=df.filter(like='Date').columns).drop(columns=df.filter(like='Time').columns))\n",
    "    \n",
    "    \n",
    "    # Split dataset by room\n",
    "    df_room1 = df.filter(like='R1')\n",
    "    df_room2 = df.filter(like='R2')\n",
    "\n",
    "    if save_csv:\n",
    "        room1_filename = f'{path_to_save}/{code_1}_WRIC_data.csv' if path_to_save else f'{code_1}_WRIC_data.csv'\n",
    "        room2_filename = f'{path_to_save}/{code_2}_WRIC_data.csv' if path_to_save else f'{code_2}_WRIC_data.csv'\n",
    "        df_room1.to_csv(room1_filename, index=False)\n",
    "        df_room2.to_csv(room2_filename, index=False)\n",
    "        \n",
    "    return df_room1, df_room2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_WRIC_file(filepath, code = \"id\", manual = None, save_csv = True, path_to_save = None):\n",
    "     \n",
    "    lines = open_file(filepath)\n",
    "    code_1, code_2, R1_metadata, R2_metadata = extract_meta_data(lines, code, manual, save_csv, path_to_save)\n",
    "    df_room1, df_room2 = create_wric_df(filepath, lines, save_csv, code_1, code_2, path_to_save)\n",
    "    \n",
    "    # TODO: Change return to return the two seperat files\n",
    "    return R1_metadata, R2_metadata, df_room1, df_room2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check and raise error if big discrepancies between measurement set 1 and 2 exist\n",
    "# TODO: Find reasonable threshold, where discrepancies are too big? - stay simple, no extravagant reports\n",
    "\n",
    "def check_discrepancies(df, threshold):\n",
    "    # Filter out environment parameters (assumed they contain these keywords)\n",
    "    env_params = ['Pressure Ambient', 'Temperature', 'Relative Humidity']\n",
    "    # TODO: Maybe do it only for energy expenditure (there simon uses delat of less than 1% I think - rest I do not know)\n",
    "    df_filtered = df.loc[:, ~df.columns.str.contains('|'.join(env_params))]\n",
    "    \n",
    "    s1_columns = df_filtered.filter(like='_S1_').columns\n",
    "    s2_columns = df_filtered.filter(like='_S2_').columns\n",
    "    print(s1_columns)\n",
    "    \n",
    "    discrepancies = []\n",
    "    \n",
    "    # Loop over the S1 and S2 column pairs\n",
    "    for s1_col, s2_col in zip(s1_columns, s2_columns):\n",
    "        s1_values = df[s1_col]\n",
    "        s2_values = df[s2_col]\n",
    "        \n",
    "        # Check if the mean variance exceeds the threshold\n",
    "        variance = np.var(np.array(s1_values)-np.array(s2_values))\n",
    "        if variance > threshold:\n",
    "            discrepancies.append(f\"{s1_col} and {s2_col} have mean variance {variance:.4f} above threshold {threshold}\")\n",
    "        else:\n",
    "            discrepancies.append(f\"{s1_col} and {s2_col} have mean variance {variance:.4f} below threshold {threshold}\")\n",
    "        \n",
    "        # Check individual values for discrepancies beyond the threshold\n",
    "        \"\"\"for i, (s1_val, s2_val) in enumerate(zip(s1_values, s2_values)):\n",
    "            if abs(s1_val - s2_val) > threshold:\n",
    "                discrepancies.append(f\"Row {i+1}: {s1_col} and {s2_col} differ by {abs(s1_val - s2_val):.4f}\")\"\"\"\n",
    "    \n",
    "    # Output the discrepancies\n",
    "    if discrepancies:\n",
    "        for discrepancy in discrepancies:\n",
    "            print(discrepancy)\n",
    "    else:\n",
    "        print(\"No discrepancies found.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "# Assuming df_room1 is the dataframe with both S1 and S2 columns\n",
    "# threshold = 0.5  # Set the desired threshold for variance and individual discrepancies\n",
    "# compare_s1_s2(df_room1, threshold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a unified dataframe by combining both measurements with various methods\n",
    "# TODO: Find best practice as default option - Simon: mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R1_metadata, R2_metadata, df_room1, df_room2 = preprocess_WRIC_file(\"C:\\Documents\\WRIC_example_data\\Results_1m_copy_anonymised.txt\", code=\"id+comment\", path_to_save=None) #path_to_save=\"C:\\Documents\\WRIC_example_data\"\n",
    "display(df_room1)\n",
    "check_discrepancies(df_room1, threshold=0.05)\n",
    "\n",
    "#TODO: Check thresholds, discrepancies etc for the various parameters (why is it so high vor kcal, but not for kjoul) -> double check calculations for mean variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
